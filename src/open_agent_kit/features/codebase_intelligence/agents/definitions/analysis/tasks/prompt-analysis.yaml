# =============================================================================
# Built-in Task: Prompt Quality Analysis
# =============================================================================
# Task for: analysis agent
#
# Analyzes user prompts for quality patterns, correlates prompt quality
# with session outcomes, and provides actionable recommendations for
# improving prompting and context engineering.
# =============================================================================

name: prompt-analysis
display_name: "Prompt Quality Analysis"
agent_type: analysis
is_builtin: true
description: >
  Analyzes user prompts for clarity, specificity, and context-richness.
  Correlates prompt quality with session outcomes and provides actionable
  recommendations for improving prompting and context engineering.

default_task: |
  Generate a prompt quality analysis report.

  Query primarily against the prompt_batches table.

  ## 1. Prompt Overview

  Use ci_query to get baseline prompt statistics from prompt_batches:
  - Total prompts analyzed (exclude null/empty user prompts)
  - Prompts per session (average, median via percentile)
  - Prompt length distribution (min, max, average character length)
  - Prompts with vs without classification

  ## 2. Prompt Quality Patterns

  Analyze prompt characteristics that correlate with good outcomes:
  - Bucket prompts by length (short/medium/long/very long) and compare
    average activity count per bucket — do longer prompts lead to more work?
  - Cross-reference classification distribution by length bucket
  - Compare prompts that lead to errors vs successful sessions

  ## 3. Common Anti-Patterns

  Identify problematic prompt patterns:
  - Very short prompts (< 20 chars) — likely vague instructions
  - Prompts without context (no file paths, no feature names)
  - Repeated similar prompts within the same session (rework indicator)
  - Prompts that correlate with high error rates in activities

  ## 4. Exemplary Prompts

  Find the best prompts from history:
  - Prompts that led to high activity count with low error rate
  - Prompts with clear classifications
  - Highlight what makes them effective (length, specificity, context)

  Use truncated previews (first 200 chars) to protect privacy while
  still being instructive.

  ## 5. Context Engineering Recommendations

  Based on the analysis, provide:
  - Specific tips for writing better prompts (based on what worked)
  - Common mistakes to avoid (based on anti-patterns found)
  - Optimal prompt length range for this project
  - Suggestions for providing better context (file paths, feature names)
  - How prompt quality has changed over time (improvement trend?)

  ## 6. Write Report

  Write an educational report that helps the user improve their
  prompting skills. Focus on actionable advice backed by their own data.

execution:
  timeout_seconds: 180
  max_turns: 50
  permission_mode: acceptEdits
  model: claude-sonnet-4-6

maintained_files:
  - path: "{project_root}/oak/insights/prompt-analysis.md"
    purpose: "Prompt quality analysis and recommendations"
    auto_create: true

ci_queries:
  discovery:
    - tool: ci_project_stats
      purpose: "Get baseline metrics"

  context:
    - tool: ci_memories
      filter: discovery
      limit: 5
      purpose: "Context about project patterns"

style:
  tone: "educational"
  include_examples: true

schema_version: 1
